## Description

A simple modular ETL (Extract â†’ Transform â†’ Normalize â†’ Outliers â†’ Encode â†’ Load) pipeline built with Python.

---

## ğŸ“ Project Structure
```markdown
DATA_PROCESSING_PIPELINE/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.toml                 # Pipeline configuration settings
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/                    # Processed datasets
â”‚   â””â”€â”€ raw/                          # Raw input datasets
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ my_pipeline/                  # Main Python package
â”‚       â”œâ”€â”€ __init__.py               # Package initializer
â”‚       â”œâ”€â”€ cli.py                    # Command-line interface
â”‚       â”œâ”€â”€ encode.py                 # Encoding & feature engineering logic
â”‚       â”œâ”€â”€ extract.py                # Data extraction functions
â”‚       â”œâ”€â”€ load.py                   # Data loading utilities
â”‚       â”œâ”€â”€ logger.py                 # Custom logging utilities
â”‚       â”œâ”€â”€ normalize.py              # Normalization logic
â”‚       â”œâ”€â”€ outliers.py               # Outlier detection and handling
â”‚       â”œâ”€â”€ profiler.py               # Profiling & performance measurement
â”‚       â”œâ”€â”€ progress.py               # Progress bar / tracking utilities
â”‚       â”œâ”€â”€ transform.py              # Data transformation pipeline
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py              # Unit tests for the pipeline
â”‚
â”œâ”€â”€ .gitignore                        # Git ignore rules
â”œâ”€â”€ LICENSE                           # License information
â”œâ”€â”€ Pipeline.ipynb                    # Jupyter notebook for pipeline demo
â”œâ”€â”€ pyproject.toml                    # Project metadata & dependencies
â””â”€â”€ README.md                         # Project documentation
```

## Data processing pipeline-> Flow Diagram
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚      RAW DATA        â”‚
                  â”‚     data/raw/        â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚       extract.py         â”‚
                â”‚  - Load raw datasets     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚      transform.py        â”‚
                â”‚  - Apply transformations |
                â”‚   (Null Imputation/Drop) |
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     normalize.py         â”‚
                â”‚  - Scale / standardize   â”‚
                â”‚    numeric features      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚      outliers.py         â”‚
                â”‚  - Detect & remove       â”‚
                â”‚    outliers              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚       encode.py          â”‚
                â”‚  - Encode categorical    â”‚
                â”‚    variables             â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     processed/           â”‚
                â”‚  (Final clean dataset)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## Installation-Guide

```bash
git clone https://github.com/deep0505sharma/Data-Processing-Pipeline.git
```
**Open VS Code terminal**
```bash
cd Data-Processing-Pipeline
#Install Dependancies
pip3 install numpy
pip3 install pandas
pip3 install scikit-learn
pip3 install tomllib
pip3 install click
pip3 install pathlib
pip3 install tqdm
#Install this project in editable model
pip3 install -e .
```
Run pipeline.ipynb file to get the processed file or feel free to use terminal to run commands built using cli
### Code Snippet
<img width="1229" height="636" alt="Image" src="https://github.com/user-attachments/assets/545b21ee-6e03-40e3-8874-9371b93aec0d" />

### CLI-Commands Use-case

-----------
| **Use Case**                                            | **Command**                                                                       |
| ------------------------------------------------------- | ----------------------------------------------------------------------------------|
| **Run full pipeline using settings.toml**               | `datapipeline run-all --config config/settings.toml`                              |
| **Run full pipeline without config**                    | `datapipeline run-all data/raw/input.csv data/processedoutput.csv`                |
| **Run only selected steps**                             | `datapipeline run --config config/settings.toml`                                  |
| **Override missing-method default in settings.toml**    | `datapipeline run --config config/settings.toml --missing-method mode`            |
| **Override steps in settings.toml**                     | `datapipeline run --config config/settings.toml --steps extract --steps trasnform`|
| **Override fill-value in settings.toml**                | `datapipeline run --config config/settings.toml --missing-method constant --fill-value 3`|
| **Override outliers-method in settings.toml**           | `datapipeline run --config config/settings.toml --outlier-method zscore --threshold 2.5`|
| **Override encode-method default in settings.toml**     | `datapipeline run --config config/settings.toml --encode-method target --target-column price`|
-----------

## ğŸ¤ Contributing

Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AddFeature`)
3. Commit your Changes (`git commit -m 'Add some new Feature'`)
4. Push to the Branch (`git push origin feature/AddFeature`)
5. Open a Pull Request

### Development Guidelines:
- Follow existing code style and conventions
- Write clear, concise commit messages
- Add comments for complex logic
- Test your changes thoroughly before submitting
- Update documentation if needed

## ğŸ› Bug/Issue Reporting
Feel free to [open an issue](https://github.com/deep0505sharma/Data-Processing-Pipeline/issues) on GitHub if you find bugs.

When reporting bugs, please include:
- Steps to reproduce the issue
- Expected vs actual behavior
- Screenshots if applicable
- Browser/device information
- error messages

## â­ Feature Request
- Feel free to [open an issue](https://github.com/deep0505sharma/Data-Processing-Pipeline/issues) on GitHub to request new features or enhancements.  
- Connect with me on [LinkedIn](https://www.linkedin.com/in/deepak-sharma-40a8781b8/) to discuss ideas and suggestions. 

### Potential Future Enhancements:
- [ ] Adding new options or methodologies for null imputation
- [ ] Support for large datasets using pyspark
- [ ] Adding option to save output in other file formats (e.g., .parquet)
